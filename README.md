# sc2 ai
stanford cs221 + 229 final project

The code is extremely messy (alas, final project code). Might get around to cleaning it up but for the meantime:
* Everything in the Replay folder is for CS 229 (Supervised Learning)
* Everything else is related to CS 221 (Reinforcement Learning)
* We used a custom mini-game for reinforcement learning, and also implemented a couple of other discretization layers for our experiments.
* We used our own replay data for the other minigame O_O
* For CS 229 - It learned something, as in how to run after the enemies
* For CS 221 - It 'kinda' learned something, but then again, we only ran for ~700 episodes/experiment? (Compared to DeepMind's something-hundred million)

Equipment used (aka, GPU):
* A GTX 1080 Ti
* A GTX 780

Reports: Final report writeups will finally be linked here (once CS 221/CS 229 have them linked on their sites)

Current Status: wip
